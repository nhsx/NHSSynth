import re
import warnings
from typing import Optional

import numpy as np
import pandas as pd
from sklearn.exceptions import ConvergenceWarning
from sklearn.mixture import BayesianGaussianMixture

from nhssynth.modules.dataloader.transformers.base import ColumnTransformer


class ClusterContinuousTransformer(ColumnTransformer):
    """
    A transformer to cluster continuous features via sklearn's `BayesianGaussianMixture`.
    Essentially wraps the process of fitting the BGM model and generating cluster assignments and normalised values for the data to comply with the `ColumnTransformer` interface.

    Args:
        n_components: The number of components to use in the BGM model.
        n_init: The number of initialisations to use in the BGM model.
        init_params: The initialisation method to use in the BGM model.
        random_state: The random state to use in the BGM model.
        max_iter: The maximum number of iterations to use in the BGM model.
        remove_unused_components: Whether to remove components that have no data assigned EXPERIMENTAL.
        clip_output: Whether to clip the output normalised values to the range [-1, 1].

    After applying the transformer, the following attributes will be populated:

    Attributes:
        means: The means of the components in the BGM model.
        stds: The standard deviations of the components in the BGM model.
        new_column_names: The names of the columns generated by the transformer (one for the normalised values and one for each cluster component).
    """

    def __init__(
        self,
        n_components: int = 3,
        n_init: int = 10,
        init_params: str = "kmeans",
        random_state: int = 0,
        max_iter: int = 1000,
        remove_unused_components: bool = False,
        clip_output: bool = False,
    ) -> None:
        super().__init__()
        self._transformer = BayesianGaussianMixture(
            n_components=n_components,
            random_state=random_state,
            n_init=n_init,
            init_params=init_params,
            max_iter=max_iter,
            weight_concentration_prior=1e-3,
        )
        self._n_components = n_components
        self._std_multiplier = 4
        self._missingness_column_name = None
        self._max_iter = max_iter
        self.remove_unused_components = remove_unused_components
        self.clip_output = clip_output

    def apply(self, data: pd.Series, constraint_adherence: Optional[pd.Series], missingness_column: Optional[pd.Series] = None) -> pd.DataFrame:
        """
        Apply the transformation to a given data column using the `BayesianGaussianMixture` model from scikit-learn.

        This method transforms the input data (`data`) by fitting a `BayesianGaussianMixture` model to the data, and normalizes the values based on the 
        learned parameters. Additionally, it handles missing data by utilizing the provided `missingness_column` and `constraint_adherence` to determine
        which rows should be included in the transformation. The resulting transformed data consists of the normalized values, along with component 
        probabilities, and a final adherence column indicating whether the data satisfies the constraints.

        If the `missingness_column` is provided, missing values are handled by assigning them to a new pseudo-cluster with a mean of 0, ensuring that 
        missing data does not affect the transformation process. Missing values are filled with zeros, and the column names are updated accordingly.

        Args:
            data (pd.Series): The input column of data to be transformed. This column is used to fit the `BayesianGaussianMixture` model.
            
            constraint_adherence (Optional[pd.Series]): A series indicating whether each row satisfies the user-defined constraints. Only rows where
                the value in `constraint_adherence` is 1 are included in the transformation process.
            
            missingness_column (Optional[pd.Series]): A series indicating missing values. If provided, missing values will be assigned to a pseudo-cluster 
                with mean 0. The missing values are handled separately to ensure that they don't interfere with the transformation.

        Returns:
            pd.DataFrame: A DataFrame containing the transformed data with the following columns:
                - `<original_column_name>_normalised`: The normalized version of the input data.
                - `<original_column_name>_c1`, ..., `<original_column_name>_cn`: Columns representing the component probabilities, where `n` is the 
                number of components in the `BayesianGaussianMixture` model.
                - The `constraint_adherence` column, which contains 1s and 0s indicating whether each row adheres to the user-defined constraints.
        
        Notes:
            - The method uses the `fit` and `predict_proba` methods of `BayesianGaussianMixture` to fit the model and calculate component probabilities.
            - If the `missingness_column` is provided, rows with missing values will be handled separately by assigning them to a pseudo-cluster with mean 0.
            - The transformed data will only include rows where the corresponding value in `constraint_adherence` is 1.
            - If `self.remove_unused_components` is set to `True`, any components that do not have any data assigned to them will be removed from the result.
            - The final output DataFrame will have integer types for the component columns and will fill missing values with 0 where necessary.
        """
        self.original_column_name = data.name
        if missingness_column is not None:
            self._missingness_column_name = missingness_column.name
            full_index = data.index
            data = data[missingness_column == 0]
            # Align constraint_adherence with the filtered data
            constraint_adherence = constraint_adherence[missingness_column == 0]
        semi_index = data.index
        data = data[constraint_adherence == 1]
        index = data.index
        data = data.fillna(0)
        data = np.array(data.values.reshape(-1, 1), dtype=data.dtype.name.lower())

        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=ConvergenceWarning)
            self._transformer.fit(data)

        self.means = self._transformer.means_.reshape(-1)
        self.stds = np.sqrt(self._transformer.covariances_).reshape(-1)

        components = np.argmax(self._transformer.predict_proba(data), axis=1)
        normalised_values = (data - self.means.reshape(1, -1)) / (self._std_multiplier * self.stds.reshape(1, -1))
        print(normalised_values)
        normalised = normalised_values[np.arange(len(data)), components]
        normalised = np.clip(normalised, -1.0, 1.0)
        print(normalised)
        components = np.eye(self._n_components, dtype=int)[components]
   
        
        transformed_data = pd.DataFrame(
            np.hstack([normalised.reshape(-1, 1), components]),
            index=index,
            columns=[f"{self.original_column_name}_normalised"]
            + [f"{self.original_column_name}_c{i + 1}" for i in range(self._n_components)],
        )
        print(transformed_data)
        # EXPERIMENTAL feature, removing components from the column matrix that have no data assigned to them
        '''if self.remove_unused_components:
            nunique = transformed_data.iloc[:, 1:].nunique(dropna=False)
            unused_components = nunique[nunique == 1].index
            unused_component_idx = [transformed_data.columns.get_loc(col_name) - 1 for col_name in unused_components]
            self.means = np.delete(self.means, unused_component_idx)
            self.stds = np.delete(self.stds, unused_component_idx)
            transformed_data.drop(unused_components, axis=1, inplace=True)
        '''

        transformed_data = pd.concat([transformed_data.reindex(semi_index).fillna(0.0), constraint_adherence], axis=1)

        if missingness_column is not None:
            transformed_data = pd.concat([transformed_data.reindex(full_index).fillna(0.0), missingness_column], axis=1)

        if 0 in transformed_data.columns:
            transformed_data = transformed_data.drop(columns=[0])
            
        self.new_column_names = transformed_data.columns
        return transformed_data.astype(
            {col_name: int for col_name in transformed_data.columns if re.search(r"_c\d+", col_name)}
        )

    def revert(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Revert data to pre-transformer state via the means and stds of the BGM. Extract the relevant columns from the data via the `new_column_names` attribute.
        If `missingness_column` was provided to the `apply` method, drop the missing values from the data before reverting and use the `full_index` to
        reintroduce missing values when `original_column_name` is constructed.

        Args:
            data: The full dataset including the column(s) to be reverted to their pre-transformer state.

        Returns:
            The dataset with a single continuous column that is analogous to the original column, with the same name, and without the generated columns from which it is derived.
        """
        working_data = data[self.new_column_names]
        full_index = working_data.index
        if self._missingness_column_name is not None:
            working_data = working_data[working_data[self._missingness_column_name] == 0]
            working_data = working_data.drop(self._missingness_column_name, axis=1)
        index = working_data.index

        components = np.argmax(working_data.filter(regex=r".*_c\d+").values, axis=1)
        working_data = working_data.filter(like="_normalised").values.reshape(-1)
        if self.clip_output:
            working_data = np.clip(working_data, -1.0, 1.0)

        mean_t = self.means[components]
        std_t = self.stds[components]
        data[self.original_column_name] = pd.Series(
            working_data * self._std_multiplier * std_t + mean_t, index=index, name=self.original_column_name
        ).reindex(full_index)
        data.drop(self.new_column_names, axis=1, inplace=True)
        return data
